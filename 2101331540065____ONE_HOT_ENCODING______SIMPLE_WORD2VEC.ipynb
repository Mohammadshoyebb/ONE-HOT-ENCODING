{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ONE-HOT ENCODING**"
      ],
      "metadata": {
        "id": "2b5c5lYo_Aww"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i12Sjox9Xpb",
        "outputId": "1cb755a3-69dc-4a8a-f924-9b10a669b132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Labels:\n",
            "[0, 1, 2, 1, 0]\n",
            "\n",
            "One-Hot Encoded Matrix:\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Example categorical data (class labels)\n",
        "class_labels = [0, 1, 2, 1, 0]\n",
        "\n",
        "# One-hot encoding using Keras to_categorical\n",
        "one_hot_encoded = to_categorical(class_labels)\n",
        "\n",
        "print(\"Original Labels:\")\n",
        "print(class_labels)\n",
        "\n",
        "print(\"\\nOne-Hot Encoded Matrix:\")\n",
        "print(one_hot_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SIMPLE WORD2VEC**"
      ],
      "metadata": {
        "id": "wKvcZqRV-cPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kFsKvlZI-irB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Corpus\n",
        "corpus = [\"I like natural language processing\", \"Word embeddings are interesting\", \"Skip-gram is a Word2Vec model\"]"
      ],
      "metadata": {
        "id": "i7fy4sbh-w6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing the corpus\n",
        "tokens = [sentence.split() for sentence in corpus]\n",
        "flatten_tokens = [word for sentence in tokens for word in sentence]\n",
        "vocab = list(set(flatten_tokens))\n",
        "vocab_size = len(vocab)"
      ],
      "metadata": {
        "id": "7_reZMyp-zFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create word-to-index and index-to-word dictionaries\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "index_to_word = {i: word for i, word in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "eJlIymns-1jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GENERATING TRAINING DATA\n",
        "window_size = 1\n",
        "\n",
        "def generate_training_data(tokens, word_to_index, window_size):\n",
        "  training_data = []\n",
        "  for sentence in tokens:\n",
        "    for i, target_word in enumerate(sentence):\n",
        "      for context_word in sentence[max(0, i - window_size):i] + sentence[i + 1:i + window_size + 1]:\n",
        "        training_data.append((word_to_index[target_word], word_to_index[context_word]))\n",
        "  return np.array(training_data)\n",
        "\n",
        "training_data = generate_training_data(tokens, word_to_index, window_size)"
      ],
      "metadata": {
        "id": "CkiYV8hN-2ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Word2Vec skip-gram model\n",
        "embedding_dim = 10\n",
        "num_negative_samples = 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras. layers. Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1, name='embedding_layer'),\n",
        "    tf.keras. layers. Reshape((embedding_dim,)),\n",
        "    tf.keras.layers. Dense(units=vocab_size, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "bB-x6SZrAtLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "target_words = training_data[:, 0]\n",
        "context_words = training_data[:, 1]\n",
        "\n",
        "model.fit(target_words, context_words, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUMD0EDQCw_K",
        "outputId": "b2cc8f01-1309-48f7-c266-027e0b5bd82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6193\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6171\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6149\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6128\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6106\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6084\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6062\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6041\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6019\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7da69063a3e0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Access learned word embedding\n",
        "word_embeddings = model.get_layer('embedding_layer').get_weights()[0]"
      ],
      "metadata": {
        "id": "5EtP73ngES_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display word embeddings\n",
        "for i, word in enumerate(vocab):\n",
        "  print(f\"{word}: {word_embeddings[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkDuIFnsC6cv",
        "outputId": "11934d84-4f03-4c5a-defd-a17178cb5a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "like: [-0.01584898  0.02639333  0.01947837 -0.02004241  0.014462    0.02284228\n",
            " -0.01243934 -0.04550199  0.03021689 -0.0228904 ]\n",
            "is: [ 0.01767459 -0.02180789  0.0550945   0.0459966   0.02170557  0.03016113\n",
            " -0.01729493  0.00394569  0.00717042  0.03056948]\n",
            "processing: [-0.06548396 -0.03083901  0.04779163  0.00963059 -0.05895626 -0.00925287\n",
            " -0.02581323  0.04552416 -0.01265028  0.00944011]\n",
            "Word2Vec: [ 0.02607585 -0.04561068  0.00207685 -0.06296484  0.04004294  0.02914419\n",
            " -0.0326288  -0.01819486 -0.01445714 -0.03039594]\n",
            "embeddings: [ 0.00535995 -0.013449   -0.02419338 -0.02730744 -0.01332071  0.00286436\n",
            "  0.05213508 -0.00260303  0.03849486 -0.06083161]\n",
            "Skip-gram: [ 0.02280479  0.00982097 -0.06151413 -0.03708856 -0.00076144  0.06512374\n",
            "  0.01678607  0.03089136  0.02266162  0.0188115 ]\n",
            "Word: [ 0.0282562   0.06555833 -0.05051512  0.02214844  0.04730291 -0.05085679\n",
            "  0.00359262 -0.00315082  0.00096763 -0.01506761]\n",
            "a: [-0.0493577  -0.03445909  0.05503394  0.02310545 -0.00438069 -0.00372183\n",
            "  0.00935117 -0.01686937 -0.06645013  0.0505004 ]\n",
            "natural: [-0.0173545  -0.05740416 -0.06021179 -0.01131136  0.02851066  0.02246694\n",
            " -0.00678339  0.00920095 -0.00118379  0.0369729 ]\n",
            "I: [ 0.03712033  0.0061048  -0.00941239  0.03867139  0.03558663  0.02187849\n",
            " -0.01222384  0.00949679 -0.06201389  0.0058797 ]\n",
            "language: [-0.01567208  0.06416534  0.00265914  0.0602535   0.00436992  0.04499049\n",
            "  0.03793584  0.0387322  -0.01496495 -0.02653422]\n",
            "interesting: [-0.00206711 -0.05079308  0.0246874  -0.00025492  0.00370081  0.00791171\n",
            "  0.04295494  0.02534656 -0.01284372 -0.06067811]\n",
            "model: [-0.02885688  0.04906469  0.00173161  0.04318506  0.01721866 -0.0011139\n",
            " -0.03224744 -0.0677309   0.00439139 -0.01923086]\n",
            "are: [-0.0103864  -0.04330471  0.00631418  0.0179484   0.01495804 -0.05939344\n",
            "  0.03304528 -0.06368978 -0.05089175  0.04525069]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6m2GvNgmEI4-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}